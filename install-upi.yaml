---
- name: dark magic
  gather_facts: false
  hosts: localhost
  vars_files:
    - "{{ playbook_dir }}/vars.yaml"

  tasks:
    - name: create cluster install config directory
      file:
        path: /tmp/{{ clustername }}
        state: "{{ state | default('directory') }}"
        mode: 0755
      when:
        - ( state is not defined ) or ( 'absent' not in state )

    - name: "Check if /tmp/{{ clustername }}/metadata.json exists"
      stat:
        path: /tmp/{{ clustername }}/metadata.json
      register: stat_result

    - name: render template
      template:
        src: files/install-config.yaml.j2
        dest: /tmp/{{ clustername }}/install-config.yaml
      when: stat_result.stat.exists == False

    - name: Create the cluster ignition configs
      command: openshift-install create ignition-configs --dir=/tmp/{{ clustername }}
      args:
        creates: /tmp/{{ clustername }}/metadata.json
      when: stat_result.stat.exists == False

    - name: read master CA info
      command: cat /tmp/{{ clustername }}/master.ign
      register: result

    - set_fact:
        master_ignition: "{{ result.stdout | from_json }}"

    - name: read Infrastructure ID from metadata.json
      command: cat /tmp/{{ clustername }}/metadata.json
      register: metadata_result

    - set_fact:
        metadata_json: "{{ metadata_result.stdout | from_json }}"

    - set_fact:
        infraid: "{{ metadata_json.infraID }}"

#    - debug:
#        msg: "{{ master_ignition.ignition.security.tls.certificateAuthorities[0].source }}"
#
#    - debug:
#        msg: "{{ metadata_json.infraID }}"
    


#todo: map state absent to mode delete
    - name: "{{ 'Create' if (state is undefined or 'absent' not in state) else 'Terminate' }} S3 bucket ( bootstrap config )"
      aws_s3:
        bucket: "{{ infraid }}-bootstrap"
        region: "{{ region }}"
        mode: "{{ state | default('create') }}"
      retries: 3
      delay: 3
      when:
        - ( state is not defined ) or ( 'absent' not in state )

    - name: upload bootstrap.ign to s3 bucket
      aws_s3:
        bucket: "{{ infraid }}-bootstrap"
        object: /bootstrap.ign
        src: /tmp/{{ clustername }}/bootstrap.ign
        mode: "{{ state | default('put') }}"
      retries: 3
      delay: 3
      when:
        - ( state is not defined ) or ( 'absent' not in state )

    - name: "{{ 'Create' if (state is undefined or 'absent' not in state) else 'Terminate' }} UPI Network Elements (Route53 & LBs)"
      cloudformation:
        stack_name: "{{ infraid }}-cluster-infra"
        state: "{{ state | default('present') }}"
        region: "{{ region }}"
        template: "files/cloudformation/02_cluster_infra.yaml.existingvpc"
        template_parameters:
          ClusterName: "{{ clustername }}"
          InfrastructureName: "{{ infraid }}"
          PrivateSubnets: "{{ privatesubnets}}"
          PrivateZoneId: "{{ privatezoneid }}"
          PublicSubnets: "{{ publicsubnets }}"
          HostedZoneId: "{{ publiczoneid }}"
          HostedZoneName: "{{ publiczonename }}"
          VpcId: "{{ vpcid }}"
        tags:
          clustername: "{{ clustername }}"
          infraid: "{{ infraid }}"
      when:
        - ( state is not defined ) or ( 'absent' not in state )
      register: cluster_infra_stack

#    - debug:
#        msg: "{{ cluster_infra_stack.stack_outputs}}"


    - name: "{{ 'Create' if (state is undefined or 'absent' not in state) else 'Terminate' }} UPI Security Elements (Security Groups & IAM)"
      cloudformation:
        stack_name: "{{ infraid }}-cluster-security"
        state: "{{ state | default('present') }}"
        region: "{{ region }}"
        template: "files/cloudformation/03_cluster_security.yaml"
        template_parameters:
          InfrastructureName: "{{ infraid }}"
          PrivateSubnets: "{{ privatesubnets}}"
          VpcId: "{{ vpcid }}"
          VpcCidr: "{{ vpccidr }}"
        tags:
          clustername: "{{ clustername }}"
          infraid: "{{ infraid }}"
      when:
        - ( state is not defined ) or ( 'absent' not in state )
      register: cluster_security_stack

#    - debug:
#        msg: "{{ cluster_security_stack.stack_outputs.MasterSecurityGroupId }}"

    - name: "{{ 'Create' if (state is undefined or 'absent' not in state) else 'Terminate' }} UPI Bootstrap (EC2 Instance, Security Groups and IAM)"
      cloudformation:
        stack_name: "{{ infraid }}-cluster-bootstrap"
        state: "{{ state | default('present') }}"
        region: "{{ region }}"
        template: "files/cloudformation/04_cluster_bootstrap.yaml"
        template_parameters:
          InfrastructureName: "{{ infraid }}"
          BootstrapIgnitionLocation: s3://{{ infraid }}-bootstrap//bootstrap.ign
          VpcId: "{{ vpcid }}"
          AutoRegisterELB: "yes"
          AllowedBootstrapSshCidr: "0.0.0.0/0"
          MasterSecurityGroupId: "{{ cluster_security_stack.stack_outputs.MasterSecurityGroupId }}"
          PublicSubnet: "{{ publicsubnets.split(',')[0] }}"
          RhcosAmi: "{{ rhcos_ami }}"
          ExternalApiTargetGroupArn: "{{ cluster_infra_stack.stack_outputs.ExternalApiTargetGroupArn }}"
          InternalApiTargetGroupArn: "{{ cluster_infra_stack.stack_outputs.InternalApiTargetGroupArn }}"
          InternalServiceTargetGroupArn: "{{ cluster_infra_stack.stack_outputs.InternalServiceTargetGroupArn }}"
          RegisterNlbIpTargetsLambdaArn: "{{ cluster_infra_stack.stack_outputs.RegisterNlbIpTargetsLambda }}"
        tags:
          clustername: "{{ clustername }}"
          infraid: "{{ infraid }}"
      when:
        - ( state is not defined ) or ( 'absent' not in state )

    - name: "{{ 'Create' if (state is undefined or 'absent' not in state) else 'Terminate' }} UPI Node Launch (EC2 master instances)"
      cloudformation:
        stack_name: "{{ infraid }}-cluster-master-nodes"
        state: "{{ state | default('present') }}"
        region: "{{ region }}"
        template: "files/cloudformation/05_cluster_master_nodes.yaml"
        template_parameters:
          InfrastructureName: "{{ infraid }}"
          AutoRegisterELB: "yes"
          MasterSecurityGroupId: "{{ cluster_security_stack.stack_outputs.MasterSecurityGroupId }}"
          Master0Subnet: "{{ privatesubnets.split(',')[0] }}"
          Master1Subnet: "{{ privatesubnets.split(',')[1] }}"
          Master2Subnet: "{{ privatesubnets.split(',')[2] }}"
          MasterInstanceProfileName: "{{ cluster_security_stack.stack_outputs.MasterInstanceProfile }}"
          MasterInstanceType: "m4.2xlarge"
          RhcosAmi: "{{ rhcos_ami }}"
          ExternalApiTargetGroupArn: "{{ cluster_infra_stack.stack_outputs.ExternalApiTargetGroupArn }}"
          InternalApiTargetGroupArn: "{{ cluster_infra_stack.stack_outputs.InternalApiTargetGroupArn }}"
          InternalServiceTargetGroupArn: "{{ cluster_infra_stack.stack_outputs.InternalServiceTargetGroupArn }}"
          RegisterNlbIpTargetsLambdaArn: "{{ cluster_infra_stack.stack_outputs.RegisterNlbIpTargetsLambda }}"
          AutoRegisterDNS: "yes"
          IgnitionLocation: "https://api.{{ clustername }}.{{ publiczonename }}:22623/config/master"
          PrivateHostedZoneId: "{{ privatezoneid }}"
#this is confusing but right for in some cases. in others use the privatezonename var
          PrivateHostedZoneName: "{{ clustername }}.{{ publiczonename }}"
          CertificateAuthorities: "{{ master_ignition.ignition.security.tls.certificateAuthorities[0].source }}"
        tags:
          clustername: "{{ clustername }}"
          infraid: "{{ infraid }}"
      when:
        - ( state is not defined ) or ( 'absent' not in state )

    - name: tag subnets
      shell: |
        aws ec2 create-tags --resources "{{ publicsubnets.split(',')[0] }}" --tags Key=kubernetes.io/cluster/{{ infraid }},Value=shared
        aws ec2 create-tags --resources "{{ publicsubnets.split(',')[1] }}" --tags Key=kubernetes.io/cluster/{{ infraid }},Value=shared
        aws ec2 create-tags --resources "{{ publicsubnets.split(',')[2] }}" --tags Key=kubernetes.io/cluster/{{ infraid }},Value=shared
      #with_sequence: start=0 count=3

    - name: "Check if /tmp/{{ clustername }}/bootstrap-complete exists"
      stat:
        path: /tmp/{{ clustername }}/bootstrap-complete
      register: bootstrap_result

    - name: Wait until bootstrap is complete
      shell: |
        set -e
        openshift-install user-provided-infrastructure bootstrap-complete --dir=/tmp/{{ clustername }}
        touch /tmp/{{ clustername }}/bootstrap-complete
      when: bootstrap_result.stat.exists == False

    - name: approve master certificates
      shell: |
        export KUBECONFIG=/tmp/{{ clustername }}/auth/kubeconfig
        oc adm certificate approve $(oc get csr -o=jsonpath="{..metadata.name}")
      ignore_errors: yes

    - fail:

    - name: delete broken machine and machineset definitions
      shell: |
        export KUBECONFIG=/tmp/{{ clustername }}/auth/kubeconfig
        #oc -n openshift-machine-api delete machineset -l machine.openshift.io/cluster-api-cluster!={{ clustername }}
        #oc -n openshift-machine-api delete machine    -l machine.openshift.io/cluster-api-machine-role=master

    - name: render machineset template
      template:
        src: files/machinesets.yaml.j2
        dest: /tmp/{{ clustername }}/machineset-{{ item.value }}.yaml
      with_dict: {a: 0, b: 1, c: 2}

    - name: import machinesets
      shell: |
        export KUBECONFIG=/tmp/{{ clustername }}/auth/kubeconfig
        oc -n openshift-machine-api create -f /tmp/{{ clustername }}/machineset-{{ item }}.yaml
      with_sequence: start=0 count=3
      ignore_errors: yes

    - name: render DNS settings
      template:
        src: files/dnses.yaml.j2
        dest: /tmp/{{ clustername }}/dnses.yaml

    - name: fix dns settings
      shell: |
        export KUBECONFIG=/tmp/{{ clustername }}/auth/kubeconfig
        oc replace -f /tmp/{{ clustername }}/dnses.yaml
        
    - name: workaround for missing kubeadmin-password file
      copy:
        dest: "/tmp/{{ clustername }}/auth/kubeadmin-password"
        content: "REDACTED, use kubeconfig instead"
        
    - name: Wait until install is complete
      command: openshift-install user-provided-infrastructure finish --dir=/tmp/{{ clustername }}

    - name: Scale ingress controller replicas
      command: oc -n openshift-ingress-operator patch ingresscontroller/default -p '{"spec":{"replicas":6}}' --type merge
      environment:
        KUBECONFIG: /tmp/{{ clustername }}/auth/kubeconfig
...
